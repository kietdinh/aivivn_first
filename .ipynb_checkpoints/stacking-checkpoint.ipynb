{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import hstack, csr_matrix, vstack\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.linear_model import *\n",
    "\n",
    "from tqdm import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "import lightgbm as lgb\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load train vÃ  test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_000000</td>\n",
       "      <td>Dung dc sp tot cam on. shop ÄÃ³ng gÃ³i sáº£n pháº©m ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_000001</td>\n",
       "      <td>Cháº¥t lÆ°á»£ng sáº£n pháº©m tuyá»‡t vá»i . Son má»‹n nhÆ°ng ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_000002</td>\n",
       "      <td>Cháº¥t lÆ°á»£ng sáº£n pháº©m tuyá»‡t vá»i nhÆ°ng k cÃ³ há»™p k...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_000003</td>\n",
       "      <td>:(( MÃ¬nh hÆ¡i tháº¥t vá»ng 1 chÃºt vÃ¬ mÃ¬nh Ä‘Ã£ ká»³ vá»...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_000004</td>\n",
       "      <td>Láº§n trÆ°á»›c mÃ¬nh mua Ã¡o giÃ³ mÃ u há»“ng ráº¥t ok mÃ  Ä‘...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                            content  label\n",
       "0  train_000000  Dung dc sp tot cam on. shop ÄÃ³ng gÃ³i sáº£n pháº©m ...      0\n",
       "1  train_000001  Cháº¥t lÆ°á»£ng sáº£n pháº©m tuyá»‡t vá»i . Son má»‹n nhÆ°ng ...      0\n",
       "2  train_000002  Cháº¥t lÆ°á»£ng sáº£n pháº©m tuyá»‡t vá»i nhÆ°ng k cÃ³ há»™p k...      0\n",
       "3  train_000003  :(( MÃ¬nh hÆ¡i tháº¥t vá»ng 1 chÃºt vÃ¬ mÃ¬nh Ä‘Ã£ ká»³ vá»...      1\n",
       "4  train_000004  Láº§n trÆ°á»›c mÃ¬nh mua Ã¡o giÃ³ mÃ u há»“ng ráº¥t ok mÃ  Ä‘...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_000000</td>\n",
       "      <td>ChÆ°a dÃ¹ng thá»­ nÃªn chÆ°a biáº¿t.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_000001</td>\n",
       "      <td>KhÃ´ng Ä‘Ã¡ng tiá»nVÃ¬ ngay Ä‘á»£t sale nÃªn má»›i mua nh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_000002</td>\n",
       "      <td>CÃ¡m Æ¡n shop. ÄÃ³ng gÃ³i sáº£n pháº©m ráº¥t Ä‘áº¹p vÃ  cháº¯c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_000003</td>\n",
       "      <td>Váº£i Ä‘áº¹p.phom oki luÃ´n.quÃ¡ Æ°ng.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_000004</td>\n",
       "      <td>Chuáº©n hÃ ng Ä‘Ã³ng gÃ³i Ä‘áº¹p.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                            content\n",
       "0  test_000000                       ChÆ°a dÃ¹ng thá»­ nÃªn chÆ°a biáº¿t.\n",
       "1  test_000001  KhÃ´ng Ä‘Ã¡ng tiá»nVÃ¬ ngay Ä‘á»£t sale nÃªn má»›i mua nh...\n",
       "2  test_000002  CÃ¡m Æ¡n shop. ÄÃ³ng gÃ³i sáº£n pháº©m ráº¥t Ä‘áº¹p vÃ  cháº¯c...\n",
       "3  test_000003                     Váº£i Ä‘áº¹p.phom oki luÃ´n.quÃ¡ Æ°ng.\n",
       "4  test_000004                           Chuáº©n hÃ ng Ä‘Ã³ng gÃ³i Ä‘áº¹p."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kietdv/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([train_df, test_df], axis=0)\n",
    "# del train_df, test_df\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "regep = re.compile(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]_*&^%$\")\n",
    "renumber = re.compile(r\"\\d+\")\n",
    "\n",
    "def transform(df):\n",
    "    df['content'] = df['content'].astype(str).fillna(' ')\n",
    "    df['content'] = df['content'].apply(lambda x: str(x).lower())\n",
    "    df['content'] = df['content'].apply(lambda x: renumber.sub('ddddd', x))\n",
    "    df['content'] = df['content'].apply(lambda x: regep.sub('', x))\n",
    "    df['content'] = df['content'].apply(lambda x: ' '.join([s for s in x.split(' ') if len(s) >= 3]))\n",
    "    df['content'] = df['content'].astype(str).fillna(' ')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "\n",
    "def extract_emojis(str):\n",
    "    return [c for c in str if c in emoji.UNICODE_EMOJI]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_df = train_df[train_df['label'] == 0]\n",
    "good_comment = good_df['content'].values\n",
    "good_emoji = []\n",
    "for c in good_comment:\n",
    "    good_emoji += extract_emojis(c)\n",
    "\n",
    "good_emoji = np.unique(np.asarray(good_emoji))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_df = train_df[train_df['label'] == 1]\n",
    "bad_comment = bad_df['content'].values\n",
    "\n",
    "bad_emoji = []\n",
    "for c in bad_comment:\n",
    "    bad_emoji += extract_emojis(c)\n",
    "\n",
    "bad_emoji = np.unique(np.asarray(bad_emoji))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['â†–', 'â†—', 'â˜€', 'â˜º', 'â™€', 'â™¥', 'âœŒ', 'âœ¨', 'âŒ', 'â£', 'â¤', 'â­', 'ğŸ†—',\n",
       "       'ğŸŒ', 'ğŸŒŸ', 'ğŸŒ§', 'ğŸŒ·', 'ğŸŒ¸', 'ğŸŒº', 'ğŸŒ¼', 'ğŸ“', 'ğŸˆ', 'ğŸ‰', 'ğŸ…', 'ğŸ¾', 'ğŸ‘‰',\n",
       "       'ğŸ‘Œ', 'ğŸ‘', 'ğŸ‘', 'ğŸ’‹', 'ğŸ’Œ', 'ğŸ’', 'ğŸ’“', 'ğŸ’•', 'ğŸ’–', 'ğŸ’—', 'ğŸ’™', 'ğŸ’š', 'ğŸ’›',\n",
       "       'ğŸ’œ', 'ğŸ’', 'ğŸ’Ÿ', 'ğŸ’¥', 'ğŸ’ª', 'ğŸ’®', 'ğŸ’¯', 'ğŸ’°', 'ğŸ“‘', 'ğŸ–¤', 'ğŸ˜€', 'ğŸ˜', 'ğŸ˜‚',\n",
       "       'ğŸ˜ƒ', 'ğŸ˜„', 'ğŸ˜…', 'ğŸ˜†', 'ğŸ˜‡', 'ğŸ˜‰', 'ğŸ˜Š', 'ğŸ˜‹', 'ğŸ˜Œ', 'ğŸ˜', 'ğŸ˜', 'ğŸ˜‘', 'ğŸ˜“',\n",
       "       'ğŸ˜”', 'ğŸ˜–', 'ğŸ˜—', 'ğŸ˜˜', 'ğŸ˜™', 'ğŸ˜š', 'ğŸ˜›', 'ğŸ˜œ', 'ğŸ˜', 'ğŸ˜', 'ğŸ˜Ÿ', 'ğŸ˜¡', 'ğŸ˜¢',\n",
       "       'ğŸ˜£', 'ğŸ˜¥', 'ğŸ˜©', 'ğŸ˜ª', 'ğŸ˜«', 'ğŸ˜¬', 'ğŸ˜­', 'ğŸ˜¯', 'ğŸ˜°', 'ğŸ˜±', 'ğŸ˜²', 'ğŸ˜³', 'ğŸ˜»',\n",
       "       'ğŸ˜¿', 'ğŸ™', 'ğŸ™‚', 'ğŸ™ƒ', 'ğŸ™„', 'ğŸ™†', 'ğŸ™Œ', 'ğŸ¤‘', 'ğŸ¤”', 'ğŸ¤—', 'ğŸ¤™', 'ğŸ¤', 'ğŸ¤£',\n",
       "       'ğŸ¤¤', '\\U0001f928', '\\U0001f92a', '\\U0001f92d'], dtype='<U1')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just remove \"sad, bad\" emoji :D\n",
    "good_emoji_fix = [\n",
    "    'â†–', 'â†—', 'â˜€', 'â˜º', 'â™€', 'â™¥', 'âœŒ', 'âœ¨', 'â£', 'â¤', 'â­', 'ğŸ†—',\n",
    "       'ğŸŒ', 'ğŸŒŸ', 'ğŸŒ§', 'ğŸŒ·', 'ğŸŒ¸', 'ğŸŒº', 'ğŸŒ¼', 'ğŸ“', 'ğŸˆ', 'ğŸ‰', 'ğŸ…', 'ğŸ¾', 'ğŸ‘‰',\n",
    "       'ğŸ‘Œ', 'ğŸ‘', 'ğŸ‘', 'ğŸ’‹', 'ğŸ’Œ', 'ğŸ’', 'ğŸ’“', 'ğŸ’•', 'ğŸ’–', 'ğŸ’—', 'ğŸ’™', 'ğŸ’š', 'ğŸ’›',\n",
    "       'ğŸ’œ', 'ğŸ’', 'ğŸ’Ÿ', 'ğŸ’¥', 'ğŸ’ª', 'ğŸ’®', 'ğŸ’¯', 'ğŸ’°', 'ğŸ“‘', 'ğŸ–¤', 'ğŸ˜€', 'ğŸ˜', 'ğŸ˜‚',\n",
    "       'ğŸ˜ƒ', 'ğŸ˜„', 'ğŸ˜…', 'ğŸ˜†', 'ğŸ˜‡', 'ğŸ˜‰', 'ğŸ˜Š', 'ğŸ˜‹', 'ğŸ˜Œ', 'ğŸ˜', 'ğŸ˜', 'ğŸ˜‘', 'ğŸ˜“', 'ğŸ˜”', \n",
    "    'ğŸ˜–', 'ğŸ˜—', 'ğŸ˜˜', 'ğŸ˜™', 'ğŸ˜š', 'ğŸ˜›', 'ğŸ˜œ', 'ğŸ˜', 'ğŸ˜', 'ğŸ˜Ÿ', 'ğŸ˜¡', 'ğŸ˜¯', 'ğŸ˜°', 'ğŸ˜±', 'ğŸ˜²', 'ğŸ˜³', 'ğŸ˜»', 'ğŸ™‚', 'ğŸ™ƒ', 'ğŸ™„', 'ğŸ™†', 'ğŸ™Œ', 'ğŸ¤‘', 'ğŸ¤”', 'ğŸ¤—',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['â˜¹', 'âœ‹', 'âŒ', 'â“', 'â¤', 'â­', 'ğŸƒ', 'ğŸ‘Œ', 'ğŸ‘', 'ğŸ‘', 'ğŸ‘¶', 'ğŸ’€', 'ğŸ’‹',\n",
       "       'ğŸ˜', 'ğŸ˜‚', 'ğŸ˜ˆ', 'ğŸ˜Š', 'ğŸ˜Œ', 'ğŸ˜', 'ğŸ˜', 'ğŸ˜‘', 'ğŸ˜’', 'ğŸ˜“', 'ğŸ˜”', 'ğŸ˜–', 'ğŸ˜š',\n",
       "       'ğŸ˜', 'ğŸ˜Ÿ', 'ğŸ˜ ', 'ğŸ˜¡', 'ğŸ˜¢', 'ğŸ˜£', 'ğŸ˜¤', 'ğŸ˜¥', 'ğŸ˜§', 'ğŸ˜©', 'ğŸ˜ª', 'ğŸ˜«', 'ğŸ˜¬',\n",
       "       'ğŸ˜­', 'ğŸ˜³', 'ğŸ˜µ', 'ğŸ˜¶', 'ğŸ™', 'ğŸ™‚', 'ğŸ™„', 'ğŸ¤”', 'ğŸ¤š', 'ğŸ¤¤'], dtype='<U1')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just remove \"good\" emoji :D\n",
    "bad_emoji_fix = [\n",
    "    'â˜¹', 'âœ‹', 'âŒ', 'â“', 'ğŸ‘', 'ğŸ‘¶', 'ğŸ’€',\n",
    "       'ğŸ˜', 'ğŸ˜‘', 'ğŸ˜’', 'ğŸ˜“', 'ğŸ˜”',\n",
    "       'ğŸ˜', 'ğŸ˜Ÿ', 'ğŸ˜ ', 'ğŸ˜¡', 'ğŸ˜¢', 'ğŸ˜£', 'ğŸ˜¤', 'ğŸ˜¥', 'ğŸ˜§', 'ğŸ˜©', 'ğŸ˜ª', 'ğŸ˜«', 'ğŸ˜¬',\n",
    "       'ğŸ˜­', 'ğŸ˜³', 'ğŸ˜µ', 'ğŸ˜¶', 'ğŸ™', 'ğŸ™„', 'ğŸ¤”',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_good_bad_emoji(row):\n",
    "    comment = row['content']\n",
    "    n_good_emoji = 0\n",
    "    n_bad_emoji = 0\n",
    "    try:\n",
    "        for c in comment:\n",
    "            if c in good_emoji_fix:\n",
    "                n_good_emoji += 1\n",
    "            if c in bad_emoji_fix:\n",
    "                n_bad_emoji += 1\n",
    "    except:\n",
    "        pass\n",
    "    row['n_good_emoji'] = n_good_emoji\n",
    "    row['n_bad_emoji'] = n_bad_emoji\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some features\n",
    "df = df.apply(count_good_bad_emoji, axis=1)\n",
    "df = transform(df)\n",
    "df['num_words'] = df['content'].apply(lambda s: len(s.split()))\n",
    "df['num_unique_words'] = df['content'].apply(lambda s: len(set(w for w in s.split())))\n",
    "df['words_vs_unique'] = df['num_unique_words'] / (df['num_words']+1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['good_bad_emoji_ratio'] = df['n_good_emoji'] / df['n_bad_emoji']\n",
    "df['good_bad_emoji_ratio'] = df['good_bad_emoji_ratio'].replace(np.nan, 0)\n",
    "df['good_bad_emoji_ratio'] = df['good_bad_emoji_ratio'].replace(np.inf, 99)\n",
    "df['good_bad_emoji_diff'] = df['n_good_emoji'] - df['n_bad_emoji']\n",
    "df['good_bad_emoji_sum'] = df['n_good_emoji'] + df['n_bad_emoji']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[~df['label'].isnull()]\n",
    "test_df = df[df['label'].isnull()]\n",
    "\n",
    "train_comments = train_df['content'].fillna(\"none\").values\n",
    "test_comments = test_df['content'].fillna(\"none\").values\n",
    "\n",
    "y_train = train_df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>n_good_emoji</th>\n",
       "      <th>n_bad_emoji</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>words_vs_unique</th>\n",
       "      <th>good_bad_emoji_ratio</th>\n",
       "      <th>good_bad_emoji_diff</th>\n",
       "      <th>good_bad_emoji_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dung tot cam on. shop Ä‘Ã³ng gÃ³i sáº£n pháº©m ráº¥t Ä‘áº¹...</td>\n",
       "      <td>train_000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cháº¥t lÆ°á»£ng sáº£n pháº©m tuyá»‡t vá»i son má»‹n nhÆ°ng kh...</td>\n",
       "      <td>train_000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>94.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cháº¥t lÆ°á»£ng sáº£n pháº©m tuyá»‡t vá»i nhÆ°ng há»™p dÃ¢y gi...</td>\n",
       "      <td>train_000002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>92.307692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>:(( mÃ¬nh hÆ¡i tháº¥t vá»ng ddddd chÃºt mÃ¬nh vá»ng cu...</td>\n",
       "      <td>train_000003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>69</td>\n",
       "      <td>79.310345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>láº§n trÆ°á»›c mÃ¬nh mua giÃ³ mÃ u há»“ng ráº¥t Ä‘á»£t nÃ y láº¡...</td>\n",
       "      <td>train_000004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>90.909091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content            id  label  \\\n",
       "0  dung tot cam on. shop Ä‘Ã³ng gÃ³i sáº£n pháº©m ráº¥t Ä‘áº¹...  train_000000    0.0   \n",
       "1  cháº¥t lÆ°á»£ng sáº£n pháº©m tuyá»‡t vá»i son má»‹n nhÆ°ng kh...  train_000001    0.0   \n",
       "2  cháº¥t lÆ°á»£ng sáº£n pháº©m tuyá»‡t vá»i nhÆ°ng há»™p dÃ¢y gi...  train_000002    0.0   \n",
       "3  :(( mÃ¬nh hÆ¡i tháº¥t vá»ng ddddd chÃºt mÃ¬nh vá»ng cu...  train_000003    1.0   \n",
       "4  láº§n trÆ°á»›c mÃ¬nh mua giÃ³ mÃ u há»“ng ráº¥t Ä‘á»£t nÃ y láº¡...  train_000004    1.0   \n",
       "\n",
       "   n_good_emoji  n_bad_emoji  num_words  num_unique_words  words_vs_unique  \\\n",
       "0             0            0         19                17        85.000000   \n",
       "1             0            0         17                17        94.444444   \n",
       "2             0            0         12                12        92.307692   \n",
       "3             0            0         86                69        79.310345   \n",
       "4             0            0         21                20        90.909091   \n",
       "\n",
       "   good_bad_emoji_ratio  good_bad_emoji_diff  good_bad_emoji_sum  \n",
       "0                   0.0                    0                   0  \n",
       "1                   0.0                    0                   0  \n",
       "2                   0.0                    0                   0  \n",
       "3                   0.0                    0                   0  \n",
       "4                   0.0                    0                   0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Táº¡o feature TFIDF Ä‘Æ¡n giáº£n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    min_df = 5, \n",
    "    max_df = 0.8, \n",
    "    max_features=10000,\n",
    "    ngram_range=(1,2),\n",
    "    use_idf=True,\n",
    "    sublinear_tf=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf.fit_transform(train_comments)\n",
    "X_test_tfidf = tfidf.transform(test_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXCLUED_COLS = ['id', 'content', 'label']\n",
    "static_cols = [c for c in train_df.columns if not c in EXCLUED_COLS]\n",
    "X_train_static = train_df[static_cols].values\n",
    "X_test_static = test_df[static_cols].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = hstack([X_train_tfidf, csr_matrix(X_train_static)]).tocsr()\n",
    "X_test = hstack([X_test_tfidf, csr_matrix(X_test_static)]).tocsr()\n",
    "# X_train = X_train_tfidf\n",
    "# X_test = X_test_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16087, 8584), (10981, 8584), (16087,))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<16087x8584 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 437027 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[ \n",
    "    ######## First level ########\n",
    "    [\n",
    "        RandomForestClassifier(n_estimators=200, min_samples_leaf=2, max_depth=30, max_features=0.7, random_state=42, n_jobs=-1),        \n",
    "        ExtraTreesClassifier (n_estimators=200, min_samples_leaf=2, max_depth=30, max_features=0.7, random_state=42, n_jobs=-1),\n",
    "        GradientBoostingClassifier(n_estimators=200, min_samples_split=2, max_depth=10, max_features=0.7, random_state=111),\n",
    "        LogisticRegression(penalty='l2', C=1.0),\n",
    "    ],\n",
    "    ######## Second level ########\n",
    "    [\n",
    "        RandomForestClassifier (n_estimators=200, min_samples_leaf=2, max_depth=30, max_features=0.7, random_state=421, n_jobs=-1)\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================== Start of Level 0 ======================\n",
      "Input Dimensionality 8584 at Level 0 \n",
      "4 models included in Level 0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kietdv/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level 0, fold 1/5 , model 0 , f1===0.789937 \n",
      "Level 0, fold 1/5 , model 1 , f1===0.796422 \n",
      "Level 0, fold 1/5 , model 2 , f1===0.854152 \n",
      "Level 0, fold 1/5 , model 3 , f1===0.865323 \n",
      "=========== end of fold 1 in level 0 ===========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kietdv/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level 0, fold 2/5 , model 0 , f1===0.810880 \n",
      "Level 0, fold 2/5 , model 1 , f1===0.806602 \n",
      "Level 0, fold 2/5 , model 2 , f1===0.864922 \n",
      "Level 0, fold 2/5 , model 3 , f1===0.881895 \n",
      "=========== end of fold 2 in level 0 ===========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kietdv/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level 0, fold 3/5 , model 0 , f1===0.805186 \n",
      "Level 0, fold 3/5 , model 1 , f1===0.794823 \n",
      "Level 0, fold 3/5 , model 2 , f1===0.865156 \n",
      "Level 0, fold 3/5 , model 3 , f1===0.869629 \n",
      "=========== end of fold 3 in level 0 ===========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kietdv/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level 0, fold 4/5 , model 0 , f1===0.801765 \n",
      "Level 0, fold 4/5 , model 1 , f1===0.811232 \n",
      "Level 0, fold 4/5 , model 2 , f1===0.863319 \n",
      "Level 0, fold 4/5 , model 3 , f1===0.875536 \n",
      "=========== end of fold 4 in level 0 ===========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kietdv/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level 0, fold 5/5 , model 0 , f1===0.804348 \n",
      "Level 0, fold 5/5 , model 1 , f1===0.811184 \n",
      "Level 0, fold 5/5 , model 2 , f1===0.858848 \n",
      "Level 0, fold 5/5 , model 3 , f1===0.874243 \n",
      "=========== end of fold 5 in level 0 ===========\n",
      "Level 0, model 0 , f1===0.802423 \n",
      "Level 0, model 1 , f1===0.804053 \n",
      "Level 0, model 2 , f1===0.861280 \n",
      "Level 0, model 3 , f1===0.873325 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kietdv/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output dimensionality of level 0 is 4 \n",
      "====================== End of Level 0 ======================\n",
      " level 0 lasted 327.976752 seconds \n",
      "====================== Start of Level 1 ======================\n",
      "Input Dimensionality 4 at Level 1 \n",
      "1 models included in Level 1 \n",
      "Level 1, fold 1/5 , model 0 , f1===0.870911 \n",
      "=========== end of fold 1 in level 1 ===========\n",
      "Level 1, fold 2/5 , model 0 , f1===0.882311 \n",
      "=========== end of fold 2 in level 1 ===========\n",
      "Level 1, fold 3/5 , model 0 , f1===0.877091 \n",
      "=========== end of fold 3 in level 1 ===========\n",
      "Level 1, fold 4/5 , model 0 , f1===0.874021 \n",
      "=========== end of fold 4 in level 1 ===========\n",
      "Level 1, fold 5/5 , model 0 , f1===0.874912 \n",
      "=========== end of fold 5 in level 1 ===========\n",
      "Level 1, model 0 , f1===0.875849 \n",
      "Output dimensionality of level 1 is 1 \n",
      "====================== End of Level 1 ======================\n",
      " level 1 lasted 18.080306 seconds \n",
      "====================== End of fit ======================\n",
      " fit() lasted 346.058426 seconds \n",
      "====================== Start of Level 0 ======================\n",
      "1 estimators included in Level 0 \n",
      "====================== Start of Level 1 ======================\n",
      "1 estimators included in Level 1 \n"
     ]
    }
   ],
   "source": [
    "from pystacknet.pystacknet import StackNetClassifier\n",
    "\n",
    "model = StackNetClassifier(\n",
    "    models, metric=\"f1\", \n",
    "    folds=5,\n",
    "    restacking=False, \n",
    "    use_retraining=True, \n",
    "    use_proba=True, \n",
    "    random_state=12345, n_jobs=1, verbose=1\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "preds=model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cls = np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"sample_submission.csv\")\n",
    "submission['label'] = pred_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_000001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_000002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_000003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_000004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  label\n",
       "0  test_000000      0\n",
       "1  test_000001      1\n",
       "2  test_000002      0\n",
       "3  test_000003      0\n",
       "4  test_000004      0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"stack_demo.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "models = [\n",
    "    RandomForestClassifier (n_estimators=100, criterion=\"entropy\", max_depth=5, max_features=0.5, random_state=1),\n",
    "    ExtraTreesClassifier (n_estimators=100, criterion=\"entropy\", max_depth=5, max_features=0.5, random_state=1),\n",
    "    GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, max_features=0.5, random_state=1),\n",
    "    LogisticRegression(random_state=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_and_predict(clf, X, y, X_test, nfolds):\n",
    "    kf = StratifiedKFold(n_splits=nfolds, shuffle=True, random_state=42)\n",
    "    \n",
    "    oof_preds = np.zeros((X.shape[0], 2))\n",
    "    sub_preds = np.zeros((X_test.shape[0], 2))\n",
    "    \n",
    "    for fold, (train_idx, valid_idx) in enumerate(kf.split(X, y)):\n",
    "        X_train, y_train = X[train_idx], y[train_idx]\n",
    "        X_valid, y_valid = X[valid_idx], y[valid_idx]\n",
    "        \n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        oof_preds[valid_idx] = clf.predict_proba(X_valid)\n",
    "        sub_preds += clf.predict_proba(X_test) / kf.n_splits\n",
    "        \n",
    "    return oof_preds, sub_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "F1 CV: 0.8028473369772468\n",
      "<class 'sklearn.ensemble.forest.ExtraTreesClassifier'>\n",
      "F1 CV: 0.8157690315898497\n",
      "<class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>\n",
      "F1 CV: 0.8664189047051398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ngxbac/anaconda3/envs/general/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "F1 CV: 0.8793558041758711\n"
     ]
    }
   ],
   "source": [
    "sub_preds = []\n",
    "\n",
    "for clf in models:\n",
    "    oof_pred, sub_pred = cross_val_and_predict(clf, X_train, y_train, X_test, nfolds=5)\n",
    "    oof_pred_cls = oof_pred.argmax(axis=1)\n",
    "    oof_f1 = f1_score(y_pred=oof_pred_cls, y_true=y_train)\n",
    "    \n",
    "    print(clf.__class__)\n",
    "    print(f\"F1 CV: {oof_f1}\")\n",
    "    \n",
    "    sub_preds.append(sub_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta cÃ³ thá»ƒ tháº¥y káº¿t quáº£ `Cross validation` cá»§a tá»«ng mÃ´ hÃ¬nh khÃ¡ giá»‘ng vá»›i cÃ¡c mÃ´ hÃ¬nh táº¡i `Layer 0` cá»§a `stacking` phÃ­a trÃªn. HÃ£y thá»­ ensemble báº±ng cÃ¡ch láº¥y trung bÃ¬nh cÃ´ng xem sao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_preds = np.asarray(sub_preds)\n",
    "sub_preds = sub_preds.mean(axis=0)\n",
    "sub_pred_cls = sub_preds.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_ensemble = submission.copy()\n",
    "submission_ensemble['label'] = sub_pred_cls\n",
    "submission_ensemble.to_csv(\"ensemble.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
