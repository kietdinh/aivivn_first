{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import hstack, csr_matrix, vstack\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.linear_model import *\n",
    "\n",
    "from tqdm import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "import lightgbm as lgb\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load train và test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_000000</td>\n",
       "      <td>Dung dc sp tot cam on. shop Đóng gói sản phẩm ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_000001</td>\n",
       "      <td>Chất lượng sản phẩm tuyệt vời . Son mịn nhưng ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_000002</td>\n",
       "      <td>Chất lượng sản phẩm tuyệt vời nhưng k có hộp k...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_000003</td>\n",
       "      <td>:(( Mình hơi thất vọng 1 chút vì mình đã kỳ vọ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_000004</td>\n",
       "      <td>Lần trước mình mua áo gió màu hồng rất ok mà đ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                            content  label\n",
       "0  train_000000  Dung dc sp tot cam on. shop Đóng gói sản phẩm ...      0\n",
       "1  train_000001  Chất lượng sản phẩm tuyệt vời . Son mịn nhưng ...      0\n",
       "2  train_000002  Chất lượng sản phẩm tuyệt vời nhưng k có hộp k...      0\n",
       "3  train_000003  :(( Mình hơi thất vọng 1 chút vì mình đã kỳ vọ...      1\n",
       "4  train_000004  Lần trước mình mua áo gió màu hồng rất ok mà đ...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_000000</td>\n",
       "      <td>Chưa dùng thử nên chưa biết.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_000001</td>\n",
       "      <td>Không đáng tiềnVì ngay đợt sale nên mới mua nh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_000002</td>\n",
       "      <td>Cám ơn shop. Đóng gói sản phẩm rất đẹp và chắc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_000003</td>\n",
       "      <td>Vải đẹp.phom oki luôn.quá ưng.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_000004</td>\n",
       "      <td>Chuẩn hàng đóng gói đẹp.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                            content\n",
       "0  test_000000                       Chưa dùng thử nên chưa biết.\n",
       "1  test_000001  Không đáng tiềnVì ngay đợt sale nên mới mua nh...\n",
       "2  test_000002  Cám ơn shop. Đóng gói sản phẩm rất đẹp và chắc...\n",
       "3  test_000003                     Vải đẹp.phom oki luôn.quá ưng.\n",
       "4  test_000004                           Chuẩn hàng đóng gói đẹp."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kietdv/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([train_df, test_df], axis=0)\n",
    "# del train_df, test_df\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "regep = re.compile(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]_*&^%$\")\n",
    "renumber = re.compile(r\"\\d+\")\n",
    "\n",
    "def transform(df):\n",
    "    df['content'] = df['content'].astype(str).fillna(' ')\n",
    "    df['content'] = df['content'].apply(lambda x: str(x).lower())\n",
    "    df['content'] = df['content'].apply(lambda x: renumber.sub('ddddd', x))\n",
    "    df['content'] = df['content'].apply(lambda x: regep.sub('', x))\n",
    "    df['content'] = df['content'].apply(lambda x: ' '.join([s for s in x.split(' ') if len(s) >= 3]))\n",
    "    df['content'] = df['content'].astype(str).fillna(' ')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "\n",
    "def extract_emojis(str):\n",
    "    return [c for c in str if c in emoji.UNICODE_EMOJI]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_df = train_df[train_df['label'] == 0]\n",
    "good_comment = good_df['content'].values\n",
    "good_emoji = []\n",
    "for c in good_comment:\n",
    "    good_emoji += extract_emojis(c)\n",
    "\n",
    "good_emoji = np.unique(np.asarray(good_emoji))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_df = train_df[train_df['label'] == 1]\n",
    "bad_comment = bad_df['content'].values\n",
    "\n",
    "bad_emoji = []\n",
    "for c in bad_comment:\n",
    "    bad_emoji += extract_emojis(c)\n",
    "\n",
    "bad_emoji = np.unique(np.asarray(bad_emoji))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['↖', '↗', '☀', '☺', '♀', '♥', '✌', '✨', '❌', '❣', '❤', '⭐', '🆗',\n",
       "       '🌝', '🌟', '🌧', '🌷', '🌸', '🌺', '🌼', '🍓', '🎈', '🎉', '🐅', '🐾', '👉',\n",
       "       '👌', '👍', '👏', '💋', '💌', '💐', '💓', '💕', '💖', '💗', '💙', '💚', '💛',\n",
       "       '💜', '💞', '💟', '💥', '💪', '💮', '💯', '💰', '📑', '🖤', '😀', '😁', '😂',\n",
       "       '😃', '😄', '😅', '😆', '😇', '😉', '😊', '😋', '😌', '😍', '😎', '😑', '😓',\n",
       "       '😔', '😖', '😗', '😘', '😙', '😚', '😛', '😜', '😝', '😞', '😟', '😡', '😢',\n",
       "       '😣', '😥', '😩', '😪', '😫', '😬', '😭', '😯', '😰', '😱', '😲', '😳', '😻',\n",
       "       '😿', '🙁', '🙂', '🙃', '🙄', '🙆', '🙌', '🤑', '🤔', '🤗', '🤙', '🤝', '🤣',\n",
       "       '🤤', '\\U0001f928', '\\U0001f92a', '\\U0001f92d'], dtype='<U1')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just remove \"sad, bad\" emoji :D\n",
    "good_emoji_fix = [\n",
    "    '↖', '↗', '☀', '☺', '♀', '♥', '✌', '✨', '❣', '❤', '⭐', '🆗',\n",
    "       '🌝', '🌟', '🌧', '🌷', '🌸', '🌺', '🌼', '🍓', '🎈', '🎉', '🐅', '🐾', '👉',\n",
    "       '👌', '👍', '👏', '💋', '💌', '💐', '💓', '💕', '💖', '💗', '💙', '💚', '💛',\n",
    "       '💜', '💞', '💟', '💥', '💪', '💮', '💯', '💰', '📑', '🖤', '😀', '😁', '😂',\n",
    "       '😃', '😄', '😅', '😆', '😇', '😉', '😊', '😋', '😌', '😍', '😎', '😑', '😓', '😔', \n",
    "    '😖', '😗', '😘', '😙', '😚', '😛', '😜', '😝', '😞', '😟', '😡', '😯', '😰', '😱', '😲', '😳', '😻', '🙂', '🙃', '🙄', '🙆', '🙌', '🤑', '🤔', '🤗',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['☹', '✋', '❌', '❓', '❤', '⭐', '🎃', '👌', '👍', '👎', '👶', '💀', '💋',\n",
       "       '😁', '😂', '😈', '😊', '😌', '😏', '😐', '😑', '😒', '😓', '😔', '😖', '😚',\n",
       "       '😞', '😟', '😠', '😡', '😢', '😣', '😤', '😥', '😧', '😩', '😪', '😫', '😬',\n",
       "       '😭', '😳', '😵', '😶', '🙁', '🙂', '🙄', '🤔', '🤚', '🤤'], dtype='<U1')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just remove \"good\" emoji :D\n",
    "bad_emoji_fix = [\n",
    "    '☹', '✋', '❌', '❓', '👎', '👶', '💀',\n",
    "       '😐', '😑', '😒', '😓', '😔',\n",
    "       '😞', '😟', '😠', '😡', '😢', '😣', '😤', '😥', '😧', '😩', '😪', '😫', '😬',\n",
    "       '😭', '😳', '😵', '😶', '🙁', '🙄', '🤔',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_good_bad_emoji(row):\n",
    "    comment = row['content']\n",
    "    n_good_emoji = 0\n",
    "    n_bad_emoji = 0\n",
    "    try:\n",
    "        for c in comment:\n",
    "            if c in good_emoji_fix:\n",
    "                n_good_emoji += 1\n",
    "            if c in bad_emoji_fix:\n",
    "                n_bad_emoji += 1\n",
    "    except:\n",
    "        pass\n",
    "    row['n_good_emoji'] = n_good_emoji\n",
    "    row['n_bad_emoji'] = n_bad_emoji\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some features\n",
    "df = df.apply(count_good_bad_emoji, axis=1)\n",
    "df = transform(df)\n",
    "df['num_words'] = df['content'].apply(lambda s: len(s.split()))\n",
    "df['num_unique_words'] = df['content'].apply(lambda s: len(set(w for w in s.split())))\n",
    "df['words_vs_unique'] = df['num_unique_words'] / (df['num_words']+1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['good_bad_emoji_ratio'] = df['n_good_emoji'] / df['n_bad_emoji']\n",
    "df['good_bad_emoji_ratio'] = df['good_bad_emoji_ratio'].replace(np.nan, 0)\n",
    "df['good_bad_emoji_ratio'] = df['good_bad_emoji_ratio'].replace(np.inf, 99)\n",
    "df['good_bad_emoji_diff'] = df['n_good_emoji'] - df['n_bad_emoji']\n",
    "df['good_bad_emoji_sum'] = df['n_good_emoji'] + df['n_bad_emoji']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[~df['label'].isnull()]\n",
    "test_df = df[df['label'].isnull()]\n",
    "\n",
    "train_comments = train_df['content'].fillna(\"none\").values\n",
    "test_comments = test_df['content'].fillna(\"none\").values\n",
    "\n",
    "y_train = train_df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>n_good_emoji</th>\n",
       "      <th>n_bad_emoji</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>words_vs_unique</th>\n",
       "      <th>good_bad_emoji_ratio</th>\n",
       "      <th>good_bad_emoji_diff</th>\n",
       "      <th>good_bad_emoji_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dung tot cam on. shop đóng gói sản phẩm rất đẹ...</td>\n",
       "      <td>train_000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chất lượng sản phẩm tuyệt vời son mịn nhưng kh...</td>\n",
       "      <td>train_000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>94.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chất lượng sản phẩm tuyệt vời nhưng hộp dây gi...</td>\n",
       "      <td>train_000002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>92.307692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>:(( mình hơi thất vọng ddddd chút mình vọng cu...</td>\n",
       "      <td>train_000003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>69</td>\n",
       "      <td>79.310345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lần trước mình mua gió màu hồng rất đợt này lạ...</td>\n",
       "      <td>train_000004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>90.909091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content            id  label  \\\n",
       "0  dung tot cam on. shop đóng gói sản phẩm rất đẹ...  train_000000    0.0   \n",
       "1  chất lượng sản phẩm tuyệt vời son mịn nhưng kh...  train_000001    0.0   \n",
       "2  chất lượng sản phẩm tuyệt vời nhưng hộp dây gi...  train_000002    0.0   \n",
       "3  :(( mình hơi thất vọng ddddd chút mình vọng cu...  train_000003    1.0   \n",
       "4  lần trước mình mua gió màu hồng rất đợt này lạ...  train_000004    1.0   \n",
       "\n",
       "   n_good_emoji  n_bad_emoji  num_words  num_unique_words  words_vs_unique  \\\n",
       "0             0            0         19                17        85.000000   \n",
       "1             0            0         17                17        94.444444   \n",
       "2             0            0         12                12        92.307692   \n",
       "3             0            0         86                69        79.310345   \n",
       "4             0            0         21                20        90.909091   \n",
       "\n",
       "   good_bad_emoji_ratio  good_bad_emoji_diff  good_bad_emoji_sum  \n",
       "0                   0.0                    0                   0  \n",
       "1                   0.0                    0                   0  \n",
       "2                   0.0                    0                   0  \n",
       "3                   0.0                    0                   0  \n",
       "4                   0.0                    0                   0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tạo feature TFIDF đơn giản"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    min_df = 5, \n",
    "    max_df = 0.8, \n",
    "    max_features=10000,\n",
    "    ngram_range=(1,2),\n",
    "    use_idf=True,\n",
    "    sublinear_tf=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf.fit_transform(train_comments)\n",
    "X_test_tfidf = tfidf.transform(test_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXCLUED_COLS = ['id', 'content', 'label']\n",
    "static_cols = [c for c in train_df.columns if not c in EXCLUED_COLS]\n",
    "X_train_static = train_df[static_cols].values\n",
    "X_test_static = test_df[static_cols].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = hstack([X_train_tfidf, csr_matrix(X_train_static)]).tocsr()\n",
    "X_test = hstack([X_test_tfidf, csr_matrix(X_test_static)]).tocsr()\n",
    "# X_train = X_train_tfidf\n",
    "# X_test = X_test_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16087, 8584), (10981, 8584), (16087,))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<16087x8584 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 437027 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[ \n",
    "    ######## First level ########\n",
    "    [\n",
    "        RandomForestClassifier(n_estimators=200, min_samples_leaf=2, max_depth=30, max_features=0.7, random_state=42, n_jobs=-1),        \n",
    "        ExtraTreesClassifier (n_estimators=200, min_samples_leaf=2, max_depth=30, max_features=0.7, random_state=42, n_jobs=-1),\n",
    "        GradientBoostingClassifier(n_estimators=200, min_samples_split=2, max_depth=10, max_features=0.7, random_state=111),\n",
    "        LogisticRegression(penalty='l2', C=1.0),\n",
    "    ],\n",
    "    ######## Second level ########\n",
    "    [\n",
    "        RandomForestClassifier (n_estimators=200, min_samples_leaf=2, max_depth=30, max_features=0.7, random_state=421, n_jobs=-1)\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================== Start of Level 0 ======================\n",
      "Input Dimensionality 8584 at Level 0 \n",
      "4 models included in Level 0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kietdv/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level 0, fold 1/5 , model 0 , f1===0.789937 \n",
      "Level 0, fold 1/5 , model 1 , f1===0.796422 \n",
      "Level 0, fold 1/5 , model 2 , f1===0.854152 \n",
      "Level 0, fold 1/5 , model 3 , f1===0.865323 \n",
      "=========== end of fold 1 in level 0 ===========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kietdv/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level 0, fold 2/5 , model 0 , f1===0.810880 \n",
      "Level 0, fold 2/5 , model 1 , f1===0.806602 \n",
      "Level 0, fold 2/5 , model 2 , f1===0.864922 \n",
      "Level 0, fold 2/5 , model 3 , f1===0.881895 \n",
      "=========== end of fold 2 in level 0 ===========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kietdv/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level 0, fold 3/5 , model 0 , f1===0.805186 \n",
      "Level 0, fold 3/5 , model 1 , f1===0.794823 \n",
      "Level 0, fold 3/5 , model 2 , f1===0.865156 \n",
      "Level 0, fold 3/5 , model 3 , f1===0.869629 \n",
      "=========== end of fold 3 in level 0 ===========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kietdv/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level 0, fold 4/5 , model 0 , f1===0.801765 \n",
      "Level 0, fold 4/5 , model 1 , f1===0.811232 \n",
      "Level 0, fold 4/5 , model 2 , f1===0.863319 \n",
      "Level 0, fold 4/5 , model 3 , f1===0.875536 \n",
      "=========== end of fold 4 in level 0 ===========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kietdv/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level 0, fold 5/5 , model 0 , f1===0.804348 \n",
      "Level 0, fold 5/5 , model 1 , f1===0.811184 \n",
      "Level 0, fold 5/5 , model 2 , f1===0.858848 \n",
      "Level 0, fold 5/5 , model 3 , f1===0.874243 \n",
      "=========== end of fold 5 in level 0 ===========\n",
      "Level 0, model 0 , f1===0.802423 \n",
      "Level 0, model 1 , f1===0.804053 \n",
      "Level 0, model 2 , f1===0.861280 \n",
      "Level 0, model 3 , f1===0.873325 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kietdv/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output dimensionality of level 0 is 4 \n",
      "====================== End of Level 0 ======================\n",
      " level 0 lasted 327.976752 seconds \n",
      "====================== Start of Level 1 ======================\n",
      "Input Dimensionality 4 at Level 1 \n",
      "1 models included in Level 1 \n",
      "Level 1, fold 1/5 , model 0 , f1===0.870911 \n",
      "=========== end of fold 1 in level 1 ===========\n",
      "Level 1, fold 2/5 , model 0 , f1===0.882311 \n",
      "=========== end of fold 2 in level 1 ===========\n",
      "Level 1, fold 3/5 , model 0 , f1===0.877091 \n",
      "=========== end of fold 3 in level 1 ===========\n",
      "Level 1, fold 4/5 , model 0 , f1===0.874021 \n",
      "=========== end of fold 4 in level 1 ===========\n",
      "Level 1, fold 5/5 , model 0 , f1===0.874912 \n",
      "=========== end of fold 5 in level 1 ===========\n",
      "Level 1, model 0 , f1===0.875849 \n",
      "Output dimensionality of level 1 is 1 \n",
      "====================== End of Level 1 ======================\n",
      " level 1 lasted 18.080306 seconds \n",
      "====================== End of fit ======================\n",
      " fit() lasted 346.058426 seconds \n",
      "====================== Start of Level 0 ======================\n",
      "1 estimators included in Level 0 \n",
      "====================== Start of Level 1 ======================\n",
      "1 estimators included in Level 1 \n"
     ]
    }
   ],
   "source": [
    "from pystacknet.pystacknet import StackNetClassifier\n",
    "\n",
    "model = StackNetClassifier(\n",
    "    models, metric=\"f1\", \n",
    "    folds=5,\n",
    "    restacking=False, \n",
    "    use_retraining=True, \n",
    "    use_proba=True, \n",
    "    random_state=12345, n_jobs=1, verbose=1\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "preds=model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cls = np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"sample_submission.csv\")\n",
    "submission['label'] = pred_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_000001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_000002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_000003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_000004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  label\n",
       "0  test_000000      0\n",
       "1  test_000001      1\n",
       "2  test_000002      0\n",
       "3  test_000003      0\n",
       "4  test_000004      0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"stack_demo.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "models = [\n",
    "    RandomForestClassifier (n_estimators=100, criterion=\"entropy\", max_depth=5, max_features=0.5, random_state=1),\n",
    "    ExtraTreesClassifier (n_estimators=100, criterion=\"entropy\", max_depth=5, max_features=0.5, random_state=1),\n",
    "    GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, max_features=0.5, random_state=1),\n",
    "    LogisticRegression(random_state=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_and_predict(clf, X, y, X_test, nfolds):\n",
    "    kf = StratifiedKFold(n_splits=nfolds, shuffle=True, random_state=42)\n",
    "    \n",
    "    oof_preds = np.zeros((X.shape[0], 2))\n",
    "    sub_preds = np.zeros((X_test.shape[0], 2))\n",
    "    \n",
    "    for fold, (train_idx, valid_idx) in enumerate(kf.split(X, y)):\n",
    "        X_train, y_train = X[train_idx], y[train_idx]\n",
    "        X_valid, y_valid = X[valid_idx], y[valid_idx]\n",
    "        \n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        oof_preds[valid_idx] = clf.predict_proba(X_valid)\n",
    "        sub_preds += clf.predict_proba(X_test) / kf.n_splits\n",
    "        \n",
    "    return oof_preds, sub_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "F1 CV: 0.8028473369772468\n",
      "<class 'sklearn.ensemble.forest.ExtraTreesClassifier'>\n",
      "F1 CV: 0.8157690315898497\n",
      "<class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>\n",
      "F1 CV: 0.8664189047051398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ngxbac/anaconda3/envs/general/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "F1 CV: 0.8793558041758711\n"
     ]
    }
   ],
   "source": [
    "sub_preds = []\n",
    "\n",
    "for clf in models:\n",
    "    oof_pred, sub_pred = cross_val_and_predict(clf, X_train, y_train, X_test, nfolds=5)\n",
    "    oof_pred_cls = oof_pred.argmax(axis=1)\n",
    "    oof_f1 = f1_score(y_pred=oof_pred_cls, y_true=y_train)\n",
    "    \n",
    "    print(clf.__class__)\n",
    "    print(f\"F1 CV: {oof_f1}\")\n",
    "    \n",
    "    sub_preds.append(sub_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta có thể thấy kết quả `Cross validation` của từng mô hình khá giống với các mô hình tại `Layer 0` của `stacking` phía trên. Hãy thử ensemble bằng cách lấy trung bình công xem sao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_preds = np.asarray(sub_preds)\n",
    "sub_preds = sub_preds.mean(axis=0)\n",
    "sub_pred_cls = sub_preds.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_ensemble = submission.copy()\n",
    "submission_ensemble['label'] = sub_pred_cls\n",
    "submission_ensemble.to_csv(\"ensemble.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
